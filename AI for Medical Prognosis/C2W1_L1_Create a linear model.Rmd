---
title: "Week 1 Labs 1: Create a Linear Model - using R"
author: "Juan Li (based on python code on Github)"
date: "04/26/2022"
output: rmarkdown::html_vignette
vignette: >
---

```{r, echo = FALSE}
knitr::opts_chunk$set(collapse=TRUE, comment="#", out.width='//textwidth')
```


## Linear model 

We'll practice using stats::lm for linear regression. You will do something similar in this week's assignment (but with a logistic regression model).  

[stats::glm](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/glm)

In R, you don't need to load the `stats` package and create an object to run `lm` and `glm`, so I will skip below two steps.

> First, import `LinearRegression`, which is a Python 'class'.
>
> Next, use the class to create an object of type LinearRegression.

Generate some data, note here I have downloaded the raw data files "X_data.csv" and "y_data.csv" from Github and saved them in the same folder as the R markdown file. 

The features in `X` are:

- Age: (years)
- Systolic_BP: Systolic blood pressure (mmHg)
- Diastolic_BP: Diastolic blood pressure (mmHg)
- Cholesterol: (mg/DL)

The labels in `y` indicate whether the patient has a disease (diabetic retinopathy).

- y = 1 : patient has retinopathy.
- y = 0 : patient does not have retinopathy.

```{r}
# Read in the whole dataset
Xdata <- read.csv("X_data.csv", header = T)
ydata <- read.csv("y_data.csv", header = T)

```

In R, it is more common to have features `X` and labels `y` in the same dataframe. And package 'dplyr' is often used for data manipulation.

```{r, message=FALSE}
# load package for manipulation 
library(dplyr)

# Generate a dataframe of features (X) and labels (y) by binding columns.
data_raw <- bind_cols(Xdata, ydata)

```

Random select 100 samples for later excercise.

```{r}
data <- sample_n(data_raw, 100)

```

Explore the data by viewing the features and the labels

```{r}
# View the features (columns 1:4). 
head(data[-5])
```

For the first histogram, I will show a base version and a ggplot2 version.

```{r, message=FALSE, fig.width = 5}
# load ggplot2
library(ggplot2)

# Plot a histogram of the Age feature 
# base version
hist(data$Age) 

# ggplot2 version: it may not be identical to the base version since they have different bin boundries.
ggplot(data, aes(Age)) + 
  geom_histogram(binwidth = 5)
```


I will only show the base version for below plots.

```{r, fig.width = 5}
# Plot a histogram of the systolic blood pressure feature 
hist(data$Systolic_BP) 
```

```{r, fig.width = 5}
# Plot a histogram of the diastolic blood pressure feature
hist(data$Diastolic_BP) 
```

```{r, fig.width = 5}
# Plot a histogram of the cholesterol feature
hist(data$Cholesterol) 
```

Also take a look at the labels

```{r, fig.width = 5}
# View a few values of the labels
head(data$y) 
```

```{r, fig.width = 5}
# Plot a histogram of the labels
hist(data$y) 
```

Fit the `lm` model using 'data'. To "fit" the model is another way of saying that we are training the model on the data.

```{r}
model <- lm(y ~ Age + Systolic_BP + Diastolic_BP + Cholesterol, data = data)

# Since you are using all features in data (except for data$y), 
# you can also write the code as below (not run):

# model <- lm(y ~ ., data = data)
```

- View the coefficients of the trained model.
- The coefficients are the 'weights' or $\beta$s associated with each feature.
- You'll use the coefficients for making predictions.
$$\hat{y} = \beta_1 x_1 + \beta_2 x_2 + ... + \beta_N x_N$$

```{r}
# View the coefficients of the model
model$coefficients

# View the summary of the model
summary(model)
```

In the assignment, you will do something similar, but using a logistic regression, so that the output of the prediction will be bounded between 0 and 1.

## This is the end of this practice section.

Please continue on with the lecture videos!